'''Workflow for the CAMP short read assembly module.'''


from contextlib import redirect_stderr
import os
from os import makedirs
from os.path import basename, join
import pandas as pd
from utils import Workflow_Dirs, ingest_samples
from collections import Counter
import pandas as pd


# Load and/or make the working directory structure
dirs = Workflow_Dirs(config['work_dir'], "enzymetrics_protein_catalog")


# Load sample names and input files 
SAMPLES = ingest_samples(config['samples'], dirs.TMP)
    
# --- Workflow output --- #

rule all:
    input:
        join(dirs.OUT, 'samples.csv')

# --- Workflow steps --- #

rule call_orfs:
    input:
        contigs=join(dirs.OUT,'assembled','{sample}','{sample}.fasta'),
    output:
        join(dirs.OUT,'bakta','{sample}','{sample}.faa'),
        join(dirs.OUT,'bakta','{sample}','{sample}.hypotheticals.tsv'),
        join(dirs.OUT,'bakta','{sample}','{sample}.log'),
        join(dirs.OUT,'bakta','{sample}','{sample}.tsv'),
        join(dirs.OUT,'bakta','{sample}','{sample}.hypotheticals.faa'),
        join(dirs.OUT,'bakta','{sample}','{sample}.embl'),
        join(dirs.OUT,'bakta','{sample}','{sample}.fna'),
        join(dirs.OUT,'bakta','{sample}','{sample}.ffn'),
        join(dirs.OUT,'bakta','{sample}','{sample}.txt'),
        join(dirs.OUT,'bakta','{sample}','{sample}.gbff'),
    log:
        join(dirs.LOG, 'bakta', '{sample}.out'),
    threads: config['call_orfs_threads'],
    resources:
        mem_mb = config['call_orfs_mem_mb'],
    params:
        outdir=join(dirs.OUT,'bakta','{sample}'),
        sam='{sample}',
        baktadb=config['baktadb']
    shell:
        """
        bakta --db {params.baktadb} --threads {threads} --output {params.outdir} --prefix {params.sam} {input.contigs} &> {log}
        """

#rule clean_annotations:
#    input:
#        expand(join(dirs.OUT,'bakta','{sample}','{sample}.tsv'),sample=SAMPLES),
#    output:
#        join(dirs.OUT,'annotations','orf_annotations.tsv'),
#    threads: 1,
#    params:
       
        
rule cluster_orfs:
    input:
        expand(join(dirs.OUT,'bakta','{sample}','{sample}.faa'),sample=SAMPLES),
    output:
        join(dirs.OUT,'mmseqs','genecat_rep_seq.fasta'),
        join(dirs.OUT,'mmseqs','genecat_cluster.tsv'),
    log:
        join(dirs.LOG,'mmseqs2','mmseqs.log'),
    threads: config['cluster_orfs_threads'],
    resources:
        mem_mb = config['cluster_orfs_mem_mb'],
    params:
        outdir=join(dirs.OUT,'mmseqs'),
        pid=config['genecat_cluster_percent_identity'],
        coverage=config['coverage'],
        mmseqs_runtype = config['mmseqs_command'],
    shell:
        """
        cat {input} > all_seq_data.faa
        mmseqs {params.mmseqs_runtype} all_seq_data.faa {params.outdir}/genecat tmp --min-seq-id {params.pid} --threads 10 -c {params.coverage} --cov-mode 1 &> {log}
        rm -rf tmp
        """

rule filter_gene_catalog:
    input:
        genecat=join(dirs.OUT,'mmseqs','genecat_rep_seq.fasta'),
        clusterfile=join(dirs.OUT,'mmseqs','genecat_cluster.tsv'),
    output:
        join(dirs.OUT,'mmseqs','genecat_rep_seq_filtered.fasta'),
    threads: config['filter_gene_catalog_threads'],
    resources:
        mem_mb = config['filter_gene_catalog_mem_mb'],
    params:
        outdir=join(dirs.OUT,'mmseqs'),
        filterprev=config['min_gene_prevalence'],
    run:
        clusters = []
        with open('{input.clusterfile}') as f:
            for line in f:
                clusters.append(line.rstrip().split('\t'))
        congenes = [x[0] for x in clusters]
        clustersize = pd.DataFrame.from_dict(Counter(congenes),orient='index')
        clustersize['sample'] = [x.split('___')[1] for x in clustersize.index]
        clustersize['contig'] = [x.split('___')[0] for x in clustersize.index]
        clustersize['gene_number'] = [x.split('___')[2] for x in clustersize.index]
        clustersize.to_csv('{params.outdir}/genecat_cluster_sizes.csv')
        tokeep = clustersize[clustersize[0]>=int('{params.filterprev}')].index
        seqs = SeqIO.to_dict(SeqIO.parse(str('{input.genecat}'), "fasta"))
        with open('{params.outdir}/genecat_rep_seq_filtered.fasta','w') as w:
            for i in tokeep:
                w.write('>' + i + '\n')
                w.wrote(str(seqs[i].seq) + '\n')

    
#rule index_gene_catalog:
        
#rule compute_relative_abundance:
 #   input:
 #       join(dirs.OUT,'mmseqs','clusters_30perc_rep_seq.fasta')
  #  output:
  #      join()
   # threads: config['index_gene_catalog_threads'],
   # resources:
   #     mem_mb = config['index_gene_catalog_mem_mb'],

rule make_config:
    input:
        join(dirs.OUT,'mmseqs','genecat_rep_seq_filtered.fasta'),
   #     join(dirs.OUT,'annotations','orf_annotations.tsv'),
    output:
        join(dirs.OUT, 'samples.csv'),
    run:
        out = []
        for i in input:
            out.append(i)
            df = pd.DataFrame(out)
        df.to_csv(str(output), index = False, header = False)



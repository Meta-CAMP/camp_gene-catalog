'''Workflow for the CAMP gene catalog module.'''


from contextlib import redirect_stderr
import os
from os.path import abspath, basename, dirname, join
import pandas as pd
import shutil
from utils import Workflow_Dirs, ingest_samples

# Load and/or make the working directory structure
dirs = Workflow_Dirs(config['work_dir'], 'gene_catalog')


# Load sample names and input files 
SAMPLES = ingest_samples(config['samples'], dirs.TMP)


# Specify the location of any external resources and scripts
dirs_ext = config['ext'] # join(dirname(abspath(__file__)), 'ext')
dirs_scr = join(dirs_ext, 'scripts')


# --- Workflow output --- #


rule all:
    input:
        join(dirs.OUT, 'final_reports', 'orf_annotations.tsv'),
        join(dirs.OUT, 'final_reports', 'orf_cluster_sizes.csv'),
        join(dirs.OUT, 'final_reports', 'orf_filt_seq.fasta'),
        join(dirs.OUT, 'final_reports', 'orf_read_cts.tsv'),
        join(dirs.OUT, 'final_reports', 'orf_rel_abund.tsv')


# --- Workflow steps --- #


rule call_orfs:
    input:
        join(dirs.TMP, '{sample}.fasta'),
    output:
        join(dirs.OUT,'0_bakta','{sample}','{sample}.tsv'),
        join(dirs.OUT,'0_bakta','{sample}','{sample}.faa'),
    log:
        join(dirs.LOG, 'bakta', '{sample}.out'),
    conda:
        join(config['env_yamls'], 'annotations.yaml'),           
    threads: config['call_orfs_threads'],
    resources:
        mem_mb = config['call_orfs_mem_mb'],
    params:
        out_dir = join(dirs.OUT, '0_bakta', '{sample}'),
        sample = '{sample}',
        bakta_db = config['bakta_db']
    shell:
        """
        bakta --force --db {params.bakta_db} --threads {threads} --output {params.out_dir} --prefix {params.sample} {input} > {log} 2>&1
        """


rule merge_sample_orfs:
    input:
        expand(join(dirs.OUT, '0_bakta','{sample}','{sample}.tsv'), sample = SAMPLES),
    output:
        join(dirs.OUT,'0_bakta', 'orf_annotations.tsv'),
    run:
        data = []
        for i in input:
            data.append(pd.read_csv(str(i), skiprows = 2,sep = '\t'))
        data = pd.concat(data)
        data.to_csv(str(output))
        

rule merge_orf_seqs:
    input:
        expand(join(dirs.OUT, '0_bakta','{sample}','{sample}.faa'), sample = SAMPLES),
    output:
        join(dirs.OUT,'0_bakta', 'orf_annotations.faa'),        
    shell:
        """
        cat {input} > {output}
        """        


rule cluster_orfs:
    input:
        join(dirs.OUT,'0_bakta', 'orf_annotations.faa'),
    output:
        join(dirs.OUT, '1_mmseqs','rep_seq.fasta'),
        join(dirs.OUT, '1_mmseqs','cluster.tsv'),
    conda:
        join(config['env_yamls'], 'annotations.yaml'),           
    log:
        join(dirs.LOG, 'mmseqs2', 'std.out'),
    threads: config['cluster_orfs_threads'],
    resources:
        mem_mb = config['cluster_orfs_mem_mb'],
    params:
        out_dir = join(dirs.OUT, '1_mmseqs'),
        pid = config['cluster_percent_identity'],
        min_cov = config['min_cluster_coverage'],
        mmseqs_mode = config['mmseqs_mode'],
    shell:
        """
        mmseqs {params.mmseqs_mode} {input} {params.out_dir}/merged {params.out_dir}/tmp --min-seq-id {params.pid} --threads {threads} -c {params.min_cov} --cov-mode 1 > {log} 2>&1
        rm -rf {params.out_dir}/tmp 
        """


rule filter_gene_catalog:
    input:
        seq = join(dirs.OUT, '1_mmseqs','rep_seq.fasta'),
        clst = join(dirs.OUT, '1_mmseqs','cluster.tsv'),
    output:
        join(dirs.OUT, '1_mmseqs', 'orf_cluster_sizes.csv'),
        join(dirs.OUT, '1_mmseqs', 'orf_filt_seq.fasta'),
    params:
        filter_script = join(dirs_scr, 'filter_gene_catalog.py'),
        out_dir = join(dirs.OUT, '1_mmseqs'),
        min_prev = config['min_gene_prevalence'],
    shell:
        """
        python {params.filter_script} {input.seq} {input.clst} {params.out_dir} {params.min_prev}
        """

    
rule index_gene_catalog:
    input:
        join(dirs.OUT, '1_mmseqs', 'orf_filt_seq.fasta'),
    output:
        join(dirs.OUT, '1_mmseqs','orf_filt_seq.dmnd'),
    conda:
        join(config['env_yamls'], 'annotations.yaml'),           
    resources:
        mem_mb = config['index_gene_catalog_mem_mb'],
    shell:
        """
        diamond makedb --db {output} --in {input} 
        """


rule concat_fastqs:
    input:
        fwd = join(dirs.TMP, '{sample}_1.fastq'),
        rev = join(dirs.TMP, '{sample}_2.fastq'),
    output:
        join(dirs.TMP, '{sample}.fastq'),
    shell:
        """
        cat {input.fwd} {input.rev} > {output}
        """

    
rule run_alignments:
    input:
        fq = join(dirs.TMP, '{sample}.fastq'),
        idx = join(dirs.OUT, '1_mmseqs','orf_filt_seq.dmnd'),
    output:
        join(dirs.TMP, '2_diamond','{sample}.tsv'),
    conda:
        join(config['env_yamls'], 'annotations.yaml'),           
    log:
        join(dirs.LOG,'diamond','{sample}.log'),
    threads: config['run_alignments_threads'],
    resources:
        mem_mb = config['run_alignments_mem_mb'],
    params:
        tmp_out = join(dirs.TMP, '2_diamond','{sample}_tmp.tsv'),
        blocksize = config['diamond_blocksize']
    shell:
        """
        diamond blastx --db {input.idx} --query {input.fq} -b {params.blocksize} -p {threads} -o {params.tmp_out} > {log} 2>&1
        cut -f2 {params.tmp_out} | sort | uniq -cd | sed "s/^[ \t]*//"| awk "{{print \$2,\$1}}" > {output}
        """


rule compute_relative_abundances:
    input:
        ann = join(dirs.OUT,'0_bakta', 'orf_annotations.tsv'),
        genes = expand(join(dirs.TMP, '2_diamond','{sample}.tsv'), sample = SAMPLES)
    output:
        join(dirs.OUT,'2_diamond','orf_read_cts.tsv'),
        join(dirs.OUT,'2_diamond','orf_rel_abund.tsv'),
    params:
        rel_abund_script = join(dirs_scr, 'compute_relative_abundances.py'),
        out_dir = join(dirs.OUT, '2_diamond'),
    shell:
        """
        python {params.rel_abund_script} {input.ann} $(echo {input.genes} | sed 's/ /,/g') {params.out_dir}
        """


rule make_config:
    input:
        join(dirs.OUT, '0_bakta', 'orf_annotations.tsv'),
        join(dirs.OUT, '1_mmseqs', 'orf_cluster_sizes.csv'),
        join(dirs.OUT, '1_mmseqs', 'orf_filt_seq.fasta'),
        join(dirs.OUT, '2_diamond','orf_read_cts.tsv'),
        join(dirs.OUT, '2_diamond','orf_rel_abund.tsv'),
    output:
        join(dirs.OUT, 'final_reports', 'orf_annotations.tsv'),
        join(dirs.OUT, 'final_reports', 'orf_cluster_sizes.csv'),
        join(dirs.OUT, 'final_reports', 'orf_filt_seq.fasta'),
        join(dirs.OUT, 'final_reports', 'orf_read_cts.tsv'),
        join(dirs.OUT, 'final_reports', 'orf_rel_abund.tsv'),
    params:
        out_dir = join(dirs.OUT, 'final_reports'),
    run:
        for i in input: 
            shutil.copy(str(i), join(params.out_dir, basename(i)))


